# ARC training config for CPU

defaults:
  - arch: hrm_v1
  - _self_

hydra:
  output_subdir: null

# Data path
# Change the data path to use our simple dataset
data_path: data/arc-simple

# Hyperparams - Training (reduced for CPU)
global_batch_size: 32  # Reduced from 768 for CPU training

epochs: 2  # Reduced from 1 to 2 for quick testing
eval_interval: 1  # Evaluate after each epoch
checkpoint_every_eval: True

lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 100  # Reduced from 2000

# Standard hyperparameter settings for LM, as used in Llama
beta1: 0.9
beta2: 0.95
weight_decay: 0.1
puzzle_emb_weight_decay: 0.1

# Hyperparams - Puzzle embeddings training
puzzle_emb_lr: 1e-2